{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83797251",
   "metadata": {},
   "source": [
    "# Model imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9518df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model for Bracket Point Prediction\n",
    "Place this file in: pointcept/models/bracket_point_model.py\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pointcept.models.builder import MODELS\n",
    "from pointcept.models.losses import build_criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f2e0b",
   "metadata": {},
   "source": [
    "# Dataset Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130a59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "#import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pointcept.datasets.builder import DATASETS\n",
    "from pointcept.datasets.transform import Compose\n",
    "import trimesh\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff643f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce2223e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BracketPointPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Model for predicting bracket_point (3D coordinate) from point clouds.\n",
    "    \n",
    "    Args:\n",
    "        backbone (dict): Backbone network config\n",
    "        criteria (list): Loss functions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, backbone, criteria):\n",
    "        super().__init__()\n",
    "        from pointcept.models.builder import build_model\n",
    "        \n",
    "        self.backbone = build_model(backbone)\n",
    "        self.criteria = build_criteria(criteria)\n",
    "        \n",
    "    def forward(self, data_dict):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            data_dict (dict): Input data dictionary containing:\n",
    "                - feat: [B, N, C] point features\n",
    "                - coord: [B, N, 3] point coordinates\n",
    "                - bracket_point: [B, 3] target bracket point (only in training)\n",
    "        \n",
    "        Returns:\n",
    "            dict: Predictions and losses\n",
    "        \"\"\"\n",
    "        # Extract features\n",
    "        feat = data_dict[\"feat\"]  # [B, N, C]\n",
    "        \n",
    "        # Forward through backbone\n",
    "        pred = self.backbone(feat)  # [B, num_classes] or needs adaptation\n",
    "        \n",
    "        # If backbone outputs per-point features, aggregate them\n",
    "        if len(pred.shape) == 3:  # [B, N, C]\n",
    "            # Global pooling: mean + max\n",
    "            pred_mean = torch.mean(pred, dim=1)  # [B, C]\n",
    "            pred_max, _ = torch.max(pred, dim=1)  # [B, C]\n",
    "            pred = torch.cat([pred_mean, pred_max], dim=1)  # [B, 2*C]\n",
    "            \n",
    "            # Add final prediction head if needed\n",
    "            if not hasattr(self, 'head'):\n",
    "                self.head = nn.Linear(pred.shape[1], 3).to(pred.device)\n",
    "            pred = self.head(pred)\n",
    "        \n",
    "        result_dict = {\"bracket_point_pred\": pred}\n",
    "        \n",
    "        # Calculate loss if in training mode\n",
    "        if self.training and \"bracket_point\" in data_dict:\n",
    "            target = data_dict[\"bracket_point\"]  # [B, 3]\n",
    "            loss = self.criteria(pred, target)\n",
    "            result_dict[\"loss\"] = loss\n",
    "        \n",
    "        return result_dict\n",
    "\n",
    "class SimplePointNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple PointNet-style backbone for regression.\n",
    "    Can be used as an alternative to PointNet++.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=6, hidden_dim=128, num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Point-wise MLPs\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Global feature extraction\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers for regression\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [B, N, C] point features\n",
    "        Returns:\n",
    "            [B, num_classes] predictions\n",
    "        \"\"\"\n",
    "        # Transpose for Conv1d: [B, C, N]\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # Feature extraction\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Global max pooling\n",
    "        x = torch.max(x, dim=2)[0]  # [B, 512]\n",
    "        \n",
    "        # Regression head\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class SimpleBracketPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple end-to-end model for bracket point prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=3, hidden_dim=128, criteria=None):\n",
    "        super().__init__()\n",
    "        self.backbone = SimplePointNet(in_channels, hidden_dim, num_classes=3)\n",
    "        self.criteria = build_criteria(criteria) if criteria else nn.MSELoss()\n",
    "        \n",
    "    def forward(self, data_dict):\n",
    "        feat = data_dict[\"coord\"]  # [B, N, C]\n",
    "        pred = self.backbone(feat)\n",
    "        \n",
    "        result_dict = {\"bracket_point_pred\": pred}\n",
    "        \n",
    "        if self.training and \"bracket_point\" in data_dict:\n",
    "            target = data_dict[\"bracket_point\"]\n",
    "            loss = self.criteria(pred, target)\n",
    "            result_dict[\"loss\"] = loss\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972ae27",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cefa57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Custom Dataset for Bracket Point Prediction from STL files\n",
    "Place this file in: pointcept/datasets/custom_bracket_dataset.py\n",
    "\"\"\"\n",
    "\n",
    "# @DATASETS.register_module()\n",
    "class BracketPointDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for predicting bracket_point from STL files.\n",
    "    \n",
    "    Args:\n",
    "        data_root (str): Root directory containing stl and json files\n",
    "        split (str): 'train', 'val', or 'test'\n",
    "        transform (list): List of transforms to apply\n",
    "        test_mode (bool): Whether in test mode\n",
    "        loop (int): Number of times to loop through dataset (for training)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root,\n",
    "        split=\"train\",\n",
    "        transform=None,\n",
    "        test_mode=False,\n",
    "        loop=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_root = data_root\n",
    "        self.split = split\n",
    "        self.transform = Compose(transform) if transform is not None else None\n",
    "        self.test_mode = test_mode\n",
    "        self.loop = loop\n",
    "        \n",
    "        # Get all STL files\n",
    "        self.data_list = self._load_data_list()\n",
    "        \n",
    "    def _load_data_list(self):\n",
    "        \"\"\"Load list of data samples.\"\"\"\n",
    "        split_file = os.path.join(self.data_root, f\"{self.split}.txt\")\n",
    "        \n",
    "        if os.path.exists(split_file):\n",
    "            # If split file exists, use it\n",
    "            with open(split_file, 'r') as f:\n",
    "                file_names = [line.strip() for line in f.readlines()]\n",
    "        else:\n",
    "            # Otherwise, use all STL files in the directory\n",
    "            file_names = [f.replace('.stl', '') for f in os.listdir(self.data_root) \n",
    "                         if f.endswith('.stl')]\n",
    "            \n",
    "            # Optionally split into train/val/test\n",
    "            # maybie need a shuffle here?\n",
    "            if self.split == 'train':\n",
    "                file_names = file_names[:int(len(file_names) * 0.8)]\n",
    "            elif self.split == 'val':\n",
    "                file_names = file_names[int(len(file_names) * 0.8):int(len(file_names) * 0.9)]\n",
    "            elif self.split == 'test':\n",
    "                file_names = file_names[int(len(file_names) * 0.9):]\n",
    "        \n",
    "        return file_names\n",
    "    \n",
    "    def _load_stl(self, stl_path):\n",
    "        \"\"\"Load STL file and extract point cloud.\"\"\"\n",
    "        mesh = trimesh.load(stl_path, force='mesh')\n",
    "        points, face_indices = trimesh.sample.sample_surface(mesh, count=1024)\n",
    "        normals = mesh.face_normals[face_indices]\n",
    "        \n",
    "        return points.astype(np.float32), normals.astype(np.float32)\n",
    "    \n",
    "    def _load_json(self, json_path):\n",
    "        \"\"\"Load JSON file and extract bracket_point.\"\"\"\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        bracket_point = np.array(data['bracket_point'], dtype=np.float32)\n",
    "        return bracket_point\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Handle looping\n",
    "        idx = idx % len(self.data_list)\n",
    "        \n",
    "        # Get file name\n",
    "        file_name = self.data_list[idx]\n",
    "        \n",
    "        # Load STL and JSON\n",
    "        stl_path = os.path.join(self.data_root, f\"{file_name}.stl\")\n",
    "        json_path = os.path.join(self.data_root, f\"{file_name}.json\")\n",
    "        \n",
    "        # Load point cloud from STL\n",
    "        coord, normal = self._load_stl(stl_path)\n",
    "        \n",
    "        # Load target bracket_point\n",
    "        bracket_point = self._load_json(json_path)\n",
    "        \n",
    "        # Create data dict\n",
    "        data_dict = {\n",
    "            \"coord\": coord,\n",
    "            \"normal\": normal,\n",
    "            \"name\": file_name,\n",
    "            \"bracket_point\": bracket_point,\n",
    "        }\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform is not None:\n",
    "            data_dict = self.transform(data_dict)\n",
    "        \n",
    "        return data_dict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list) * self.loop\n",
    "\n",
    "\n",
    "# Optional: Custom collate function if needed\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for batching.\"\"\"\n",
    "    # Stack coordinates, normals, and bracket_points\n",
    "    coords = torch.stack([torch.from_numpy(item['coord']) for item in batch])\n",
    "    normals = torch.stack([torch.from_numpy(item['normal']) for item in batch])\n",
    "    bracket_points = torch.stack([torch.from_numpy(item['bracket_point']) for item in batch])\n",
    "    \n",
    "    batch_dict = {\n",
    "        'coord': coords,\n",
    "        'normal': normals,\n",
    "        'bracket_point': bracket_points,\n",
    "        'name': [item['name'] for item in batch],\n",
    "    }\n",
    "    \n",
    "    # Include any other keys from transforms\n",
    "    for key in batch[0].keys():\n",
    "        if key not in ['coord', 'normal', 'bracket_point', 'name']:\n",
    "            if isinstance(batch[0][key], np.ndarray):\n",
    "                batch_dict[key] = torch.stack([torch.from_numpy(item[key]) for item in batch])\n",
    "    \n",
    "    return batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e84ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BracketPointDataset(\"/work/grana_maxillo/Mlugli/brackets_melted/flattened\", \"val\")\n",
    "train_loader = DataLoader(dataset, batch_size = 4, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(train_loader):\n",
    "    print(f\"{i}/{len(train_loader)}\")\n",
    "    data_dict = {k: v.cuda() if torch.is_tensor(v) else v for k, v in x.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ab701af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointcept.models.builder import build_model\n",
    "from torch_scatter import segment_csr  \n",
    "from pointcept.models.utils.structure import Point  \n",
    "\n",
    "class VoxelBracketPredictor(nn.Module):  \n",
    "    \"\"\"  \n",
    "    Voxel-based backbone + regression head for 3D point prediction.  \n",
    "    \"\"\"  \n",
    "      \n",
    "    def __init__(  \n",
    "        self,\n",
    "        backbone,  \n",
    "        backbone_out_channels=96,  \n",
    "        output_dim=3,  # 3D point coordinates  \n",
    "    ):  \n",
    "        super().__init__()  \n",
    "          \n",
    "        self.backbone = build_model(backbone)  \n",
    "          \n",
    "        # Regression head: outputs 3D point coordinates  \n",
    "        self.head = nn.Sequential(  \n",
    "            nn.Linear(backbone_out_channels, 256),  \n",
    "            nn.BatchNorm1d(256),  \n",
    "            nn.ReLU(inplace=True),  \n",
    "            nn.Dropout(p=0.3),  \n",
    "            nn.Linear(256, 128),  \n",
    "            nn.BatchNorm1d(128),  \n",
    "            nn.ReLU(inplace=True),  \n",
    "            nn.Dropout(p=0.3),  \n",
    "            nn.Linear(128, output_dim),  \n",
    "        )  \n",
    "      \n",
    "    def forward(self, input_dict):    \n",
    "        # Pass through backbone    \n",
    "        point = self.backbone(input_dict)    \n",
    "            \n",
    "        # Handle Point structure from voxel-based backbones    \n",
    "        if isinstance(point, Point):    \n",
    "            # Global average pooling across all points    \n",
    "            point.feat = segment_csr(    \n",
    "                src=point.feat,    \n",
    "                indptr=nn.functional.pad(point.offset, (1, 0)),    \n",
    "                reduce=\"mean\",    \n",
    "            )    \n",
    "            feat = point.feat    \n",
    "        else:    \n",
    "            feat = point    \n",
    "            \n",
    "        # Predict 3D point    \n",
    "        bracket_point_pred = self.head(feat)    \n",
    "            \n",
    "        out = {\"bracket_point_pred\": bracket_point_pred}  # Add predictions to output  \n",
    "        \n",
    "        # Compute MSE loss if ground truth available    \n",
    "        if \"bracket_point\" in input_dict:    \n",
    "            target = input_dict[\"bracket_point\"]    \n",
    "            loss = nn.functional.mse_loss(bracket_point_pred, target)    \n",
    "            out[\"loss\"] = loss    \n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bbaa607",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VoxelBracketPredictor(    \n",
    "    backbone=dict(  \n",
    "        type=\"SpUNet-v1m1\",  \n",
    "        in_channels=3,  # xyz coordinates only  \n",
    "        num_classes=0,  \n",
    "        channels=(32, 64, 128, 256, 256, 128, 96, 96),  \n",
    "        layers=(2, 3, 4, 6, 2, 2, 2, 2),  \n",
    "    ),  \n",
    "    backbone_out_channels=96,  \n",
    "    output_dim=3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34121cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand()\n",
    "# need to know the shape of the input first."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pointcept venv",
   "language": "python",
   "name": "pointcept-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
